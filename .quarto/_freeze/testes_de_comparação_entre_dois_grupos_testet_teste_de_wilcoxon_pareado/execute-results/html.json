{
  "hash": "d9940573a99cee17ae9656429545fd23",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Testes de comparação entre dois grupos (Teste-t & teste de Wilcoxon pareado)\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)    # Importar dados do Google Sheets\nlibrary(dplyr)     # Manipulação de dados (filter, select, pull, etc.)\nlibrary(tidyr)     # Pivot_wider para transformar dados\nlibrary(ggplot2)   # Gráficos com ggplot (usado via tidyverse ou separadamente)\nlibrary(ggpubr)    # ggboxplot e stat_pvalue_manual para visualização e p-valor no gráfico\nlibrary(report)    # Relatório interpretado do teste t\nlibrary(rstatix)   # Funções de teste estatístico, como t_test()\n```\n:::\n\n\n\n# **Teste-t**\n\nO teste t-Student, ou simplesmente teste-t, é o método mais utilizado para se avaliar as diferenças entre as médias entre dois grupos. É um teste de hipótese que usa conceitos estatísticos para rejeitar ou não uma hipótese nula quando a estatística de teste (t) segue uma distribuição *t* de Student.\n\nAs hipóteses formuladas em um teste-t comparam as médias entre dois grupos, podendo estas serem dependentes ou independentes.\n\n-   **Hipótese nula (Ho)**: a média do grupo 1 é igual a média do grupo 2\n\n-   **Hipótese alternativa (Ha)**: a média do grupo 1 é diferente da média do grupo 2\n\nTendo formulado as hipóteses, o teste-t irá calcular o valor de *t* e vai aplicá-lo à função densidade de probabilidade da distribuição *t* de Student medindo o tamanho da área abaixo dessa função para valores maiores ou iguais a *t*. Essa área representa a probabilidade da média dessa(s) amostra(s) em questão ter(em) apresentado o(s) valor(es) observado(s) ou algo mais extremo. Se a probabilidade desse resultado ter ocorrido for muito pequena, podemos concluir que o resultado observado é estatisticamente relevante. Essa probabilidade também é chamada de p-valor ou valor *p*.\n\nCaso o nível de significância do p-valor for de 5% e a área abaixo da função densidade de probabilidade da distribuição *t* de Student seja menor do que 5%, pode-se afirmar que a hipótese nula é rejeitada com nível de confiança de 95%.\n\nNote que não rejeitar a hipótese nula não é a mesma coisa que afirmar que a hipótese alternativa é válida com o mesmo nível de confiança. Isso seria uma interpretação incorreta do teste.\n\n## **Importação de dados**\n\nO conjunto de dados foi importado do Google Sheet usando a função `gsheet2tbl()` do pacote `gsheet`. Nesse conjunto existem dois grupos independentes: um grupo de plantas em que foi aplicado Mg2 e um grupo de plantas controle (sem aplicação).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_mg <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\n```\n:::\n\n\n\nPodemos observar que o conjunto de dados está no formato longo. Para o teste-t, é preciso que os dados estejam no formato largo, portanto eles serão transformados através da função `pivot_wider()`.\n\n### Visualização inicial\n\n## Reorganização dos dados para Teste T\n\nA transformação para formato largo com é necessária para testes que comparam variáveis emparelhadas.\n\n-   Usou-se `pivot_wider()` para transformar os dados de formato longo para largo, criando colunas separadas para `control` e `Mg2`;\n\n-   Removeu-se a coluna `rep`;\n\n-   Usou-se `attach()` para facilitar o acesso direto às variáveis `Mg2` e `control`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\ndat_mg2 <- dat_mg |> \n  pivot_wider(names_from = trat, values_from = comp) |> \ndplyr::select(-rep)\n\nattach(dat_mg2)\n```\n:::\n\n\n\n## Teste T\n\n### Teste T básico com `t.test`\n\nO teste t de Student compara médias de dois grupos independentes. A implementação padrão no R utiliza a correção de Welch, que não assume igualdade de variâncias, tornando-o robusto mesmo quando esse pressuposto é violado. A direção da comparação (grupo A vs B ou B vs A) não altera a magnitude da diferença, apenas o sinal do valor t.\n\n-   O segundo teste foi armazenado em `t_results` para reutilização.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(Mg2, control) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  Mg2 and control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n```\n\n\n:::\n\n```{.r .cell-code}\nt_results <- t.test(control, Mg2)\n```\n:::\n\n\n\n#### Relatório com `report`\n\n`report(t_results)`: gera uma descrição interpretada do teste, facilitando a compreensão dos resultados.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(report) \nreport(t_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between control and Mg2\n(mean of x = 15.68, mean of y = 10.52) suggests that the effect is positive,\nstatistically significant, and large (difference = 5.16, 95% CI [3.83, 6.49],\nt(17.35) = 8.15, p < .001; Cohen's d = 3.65, 95% CI [2.14, 5.12])\n```\n\n\n:::\n:::\n\n\n\n### Teste T com `rstatix`\n\n`t_test(comp ~ trat, data = dat_mg)`: aplica o teste t com sintaxe mais legível.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstatix) \ntest <- t_test(comp ~ trat, data = dat_mg)\n```\n:::\n\n\n\n### Visualização de dados com valor de p\n\nAtravés do boxplot é possível assumir visualmente que os grupos seguem uma distribuição normal (pela simetria do boxplot formado) e que possuem variância homogênea (a estrutura dos dois boxplot são similares), mas os testes de premissas ainda devem ser feitos para confirmar.\n\n-   `ggboxplot()` cria boxplots coloridos por grupo;\n\n-   `stat_pvalue_manual()` adiciona o valor-p diretamente no gráfico. A inclusão do valor-p no gráfico proporciona contexto imediato aos resultados estatísticos.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggpubr)\np <- ggboxplot (\n  dat_mg, x = \"trat\", y = \"comp\", color = \"trat\", palette = \"jco\")\n# Add the p-value manually\np + stat_pvalue_manual(test, label =\"p\", y.position = 18)+ylim(0,20)\n```\n\n::: {.cell-output-display}\n![](testes_de_comparação_entre_dois_grupos_testet_teste_de_wilcoxon_pareado_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n### Salvar imagem\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggsave(\"plot2.png\")\n```\n:::\n\n\n\n## Verificação de Pressupostos do Teste T\n\nAntes de aplicar o teste t, é importante garantir que os dados sigam seus pressupostos:\n\n### Normalidade\n\nOs testes de normalidade (Shapiro-Wilk) avaliam formalmente se a distribuição dos dados desvia-se significativamente da distribuição normal. Esta verificação é crucial porque o teste t assume que os resíduos seguem distribuição normal. Porém, em amostras pequenas (\\<30 observações), esses testes têm baixo poder estatístico, sendo mais informativos os diagnósticos visuais como QQ-plots e histogramas.\n\n-   `shapiro.test(Mg2)` e `shapiro.test(control)` testam se os dados têm distribuição normal;\n\n-   `hist()` permite ver graficamente a forma da distribuição.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(Mg2) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  Mg2\nW = 0.97269, p-value = 0.9146\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(control) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  control\nW = 0.93886, p-value = 0.5404\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(Mg2) \n```\n\n::: {.cell-output-display}\n![](testes_de_comparação_entre_dois_grupos_testet_teste_de_wilcoxon_pareado_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(control)\n```\n\n::: {.cell-output-display}\n![](testes_de_comparação_entre_dois_grupos_testet_teste_de_wilcoxon_pareado_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n:::\n\n\n\n### Homogeneidade de variâncias\n\nO teste F de variâncias verifica a homocedasticidade (igualdade de variâncias entre grupos), pressuposto essencial para o teste t clássico. Quando rejeitado (p \\< 0.05), recomenda-se manter o teste t de Welch, que é robusto a heterocedasticidade. Alternativamente, o teste de Levene é menos sensível a desvios de normalidade.\n\n-   `var.test(dat_Mg2, control)` verifica se os dois grupos possuem variâncias semelhantes, o que é esperado no teste t clássico.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar.test(dat_mg2$Mg2, dat_mg2$control)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  dat_mg2$Mg2 and dat_mg2$control\nF = 1.4781, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3671417 5.9508644\nsample estimates:\nratio of variances \n          1.478111 \n```\n\n\n:::\n:::\n\n\n\nSe esses pressupostos não forem atendidos, outras abordagens são necessárias (ex: teste de Wilcoxon).\n\n## Teste T pareado (Escala)\n\nEm desenhos experimentais com medidas repetidas (como \"antes-depois\"), o teste t pareado considera a correlação intrínseca entre as observações, aumentando o poder estatístico. O teste de Wilcoxon pareado (não-paramétrico) é alternativa quando os pressupostos de normalidade não são atendidos, comparando medianas em vez de médias.\n\n#### Importação e visualização de dados\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nescala <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=1729131173#gid=1729131173\")  \nescala |> ggplot(aes(assessment, acuracia)) +   geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](testes_de_comparação_entre_dois_grupos_testet_teste_de_wilcoxon_pareado_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\nApenas pelo gráfico é possível observar que a estutura dos dois grupos é diferente um do outro, podendo indicar variâncias heterogêneas.\n\nA função `pivot_wider()` foi usada para transformar o conjunto de dados de formato longo para formato largo.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nescala2 <- escala |>\n  dplyr::select(assessment, rater, acuracia) |>\n  tidyr::pivot_wider(names_from = assessment, values_from = acuracia)\n```\n:::\n\n\n\n#### **Teste de premissas**\n\nFoi usada a função `shapiro.test()` para cada grupo para determinar se eles seguem normalidade ou não.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(escala2$Unaided)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(escala2$Aided1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n```\n\n\n:::\n:::\n\n\n\n-   Como **p \\> 0.05** (neste caso, **p = 0.4335**), **não rejeitamos a hipótese nula**. O teste diz que os dados da coluna `Aided1` **não estão muito distantes de uma curva normal**, então pode-se, em geral, **usar testes paramétricos** (como o **teste t**) com essa variável.\n\n-   Como **p \\< 0.05** (neste caso, **p = 0.007**), **rejeitamos a hipótese nula**. Os dados da variável `Unaided` **não têm uma distribuição normal**. Portanto, para realizar testes estatísticos envolvendo essa variável, deve-se considerar o uso de **testes não paramétrico.**\n\n    Em seguida foi realizado o teste de variância pela função `var.test()`.\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    var.test(escala2$Unaided, escala2$Aided1)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    \n    \tF test to compare two variances\n    \n    data:  escala2$Unaided and escala2$Aided1\n    F = 20.978, num df = 9, denom df = 9, p-value = 0.000106\n    alternative hypothesis: true ratio of variances is not equal to 1\n    95 percent confidence interval:\n      5.210754 84.459185\n    sample estimates:\n    ratio of variances \n              20.97847 \n    ```\n    \n    \n    :::\n    :::\n\n\n\n<!-- -->\n\n-   Como **p \\< 0.05**, **rejeitamos a hipótese nula**. Os dados mostram que a dispersão (variação) dos valores em `Unaided` é **muito maior** do que em `Aided1`, e essa diferença **é estatisticamente significativa**.\n\n#### Teste-t pareado\n\nPara este caso de conjunto de dados onde os dois grupos são dependentes e apresentam variâncias heterogêneas, o teste-t é realizado com a função `t.test()` usando os argumentos `paired = TRUE` e `var.equal = FALSE`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_test(acuracia ~ assessment, data = escala, paired = TRUE, var.equal = FALSE) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 8\n  .y.      group1 group2     n1    n2 statistic    df       p\n* <chr>    <chr>  <chr>   <int> <int>     <dbl> <dbl>   <dbl>\n1 acuracia Aided1 Unaided    10    10      4.42     9 0.00167\n```\n\n\n:::\n:::\n\n\n\nComo o p-valor foi inferior ao nível de significância, rejeitamos a hipótese nula de que os dois grupos são iguais.\n\n### Análise separada dos grupos\n\n-   `escala` foi importado com `gsheet2tbl()`.\n\n-   `t_test(acuracia ~ assessment, paired = TRUE)`: compara a acurácia com e sem intervenção.\n\n-   `ggplot` com `geom_boxplot()` mostra visualmente essa comparação;\n\n-   `unaided` e `aided` foram criados com `filter()` e `pull()`.\n\n-   Aplicaram-se testes de normalidade (`shapiro.test()`), variância (`var.test()`), seguido de:\n\n    -   `t.test(unaided, aided, paired = TRUE)`\n\n    -   `wilcox.test(unaided, aided = FALSE)`: caso não haja normalidade (teste não paramétrico).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Carregar pacotes necessários\nlibrary(dplyr)\n\n# Separar os vetores de acurácia para os dois tipos de avaliação\nunaided <- escala |>\n  dplyr::filter(assessment == \"Unaided\") |>\n  dplyr::select(acuracia) |>\n  dplyr::pull()\n\naided <- escala |>\n  dplyr::filter(assessment == \"Aided1\") |>\n  dplyr::select(acuracia) |>\n  dplyr::pull()\n\n# Teste F para comparar variâncias\nvar.test(unaided, aided)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  unaided and aided\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Testes de normalidade (Shapiro-Wilk)\nshapiro.test(unaided)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  unaided\nW = 0.7748, p-value = 0.007155\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(aided)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  aided\nW = 0.92852, p-value = 0.4335\n```\n\n\n:::\n\n```{.r .cell-code}\n# Teste t pareado (sem assumir variâncias iguais)\nt.test(unaided, aided, paired = TRUE, var.equal = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  unaided and aided\nt = -4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.3552353 -0.1147647\nsample estimates:\nmean difference \n         -0.235 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Teste de Wilcoxon pareado (alternativa não paramétrica ao t pareado)\nwilcox.test(unaided, aided, paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  unaided and aided\nV = 0, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n```\n\n\n:::\n:::\n\n\n\nFoi realizada uma comparação entre os desempenhos nas condições *unaided* (sem ajuda) e *aided* (com ajuda) utilizando dados de acurácia. Inicialmente, o teste de Shapiro-Wilk indicou que os dados da condição *unaided* não seguem uma distribuição normal (p = 0,007), enquanto os dados da condição *aided* não apresentaram evidência significativa de desvio da normalidade (p = 0,433), sugerindo distribuição aproximadamente normal.\n\nEm seguida, o teste F para comparação de variâncias revelou que as variâncias entre as duas condições são significativamente diferentes (p = 0,0001), com a variância da condição *unaided* sendo consideravelmente maior. Esse resultado viola o pressuposto de homogeneidade de variâncias necessário para alguns testes paramétricos.\n\nApesar disso, o teste t pareado, que compara as médias das duas condições assumindo pares de medidas (por exemplo, do mesmo indivíduo), indicou uma diferença estatisticamente significativa entre *unaided* e *aided* (p = 0,0017). A média da acurácia foi maior na condição *aided*, com uma diferença média de aproximadamente 0,235 unidades, indicando melhora no desempenho com o uso da ajuda.\n\nComo a distribuição dos dados da condição *unaided* não é normal e há diferença de variâncias, foi também realizado o teste de Wilcoxon pareado, que é uma alternativa não paramétrica ao teste t. Esse teste também indicou uma diferença significativa entre as duas condições (p = 0,0059), confirmando que os participantes apresentaram desempenho significativamente melhor na condição *aided*.\n\nEm conjunto, os resultados sugerem de forma robusta que o uso de ajuda (condição *aided*) melhora significativamente a acurácia em relação à condição sem ajuda (*unaided*), mesmo considerando a ausência de normalidade e a diferença de variâncias nos dados.\n",
    "supporting": [
      "testes_de_comparação_entre_dois_grupos_testet_teste_de_wilcoxon_pareado_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}